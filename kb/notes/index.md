---
description: Auto-generated directory — run scripts/generate_notes_index.py /home/zby/llm/commonplace/kb/notes to rebuild
type: index
---

# Notes Directory

- [ADR-001: Generate Topic links from frontmatter](./001-generate-topic-links-from-frontmatter.md)
- [A functioning claw needs a workshop layer, not just a library](./a-functioning-claw-needs-a-workshop-layer-not-just-a-library.md) *(note)* — The current type system models permanent knowledge (library) but not in-flight work with state machines, dependencies, and expiration (workshop) — tasks are a prototype of the missing layer, and a functioning claw needs both plus bridges between them
- [Ad hoc prompts extend the system without schema changes](./ad-hoc-prompts-extend-the-system-without-schema-changes.md) *(note)* — When a new requirement doesn't fit existing types or skills, writing an ad hoc instructions note absorbs it without any schema change — the collections problem is a concrete example
- [002-inline-global-types-in-writing-guide](./adr/002-inline-global-types-in-writing-guide.md) *(adr)* — Decision to inline note and structured-claim templates into WRITING.md so the agent gets type structure and writing conventions in a single hop — eliminates one read for the two most common note types
- [Agent statelessness makes skill layers architectural, not pedagogical](./agent-statelessness-makes-skill-layers-architectural-not-pedagogical.md) *(structured-claim)* — The methodology→skill relationship is permanent infrastructure for LLM agents, not a learning progression — because agents never internalize, the two tiers serve different consumers (design-time reasoning vs runtime execution) and lossy compilation creates systematic blind spots
- [Agent statelessness means the harness should inject context automatically](./agent-statelessness-means-harness-should-inject-context-automatically.md) *(structured-claim)* — Since agents can't carry vocabulary or decisions between reads, the harness should auto-inject referenced context — definitions once per session, ADRs when relevant. The trigger mechanism (type, link semantics, term detection) is an open question; the need follows directly from statelessness.
- [Agentic systems interpret underspecified instructions](./agentic-systems-interpret-underspecified-instructions.md) *(note)* — LLM-based systems have two distinct properties — semantic underspecification of natural language specs (the deeper difference from traditional programming) and execution indeterminism (present in all practical systems) — the spec-to-program projection model captures the first, which indeterminism tends to obscure
- [Agentic systems learn through three distinct mechanisms](./agentic-systems-learn-through-three-distinct-mechanisms.md) *(structured-claim)* — Deployed agentic systems learn through three distinct mechanisms — stabilisation (committing to an interpretation of an underspecified spec), crystallisation (prompt→code phase transition), and distillation (extracting procedures from reasoning in the same medium). All are capacity change per Simon; they differ in what changes and whether the medium transitions.
- [Agents navigate by deciding what to read next](./agents-navigate-by-deciding-what-to-read-next.md) *(note)* — An agent doing a task navigates by deciding what to read — links, index entries, search tools, and skill descriptions are all pointers with varying amounts of context for that decision
- [Alexander's patterns connect to knowledge system design at multiple levels](./alexander-patterns-and-knowledge-system-design.md) *(note)* — Christopher Alexander's pattern language, generative processes, and centers may connect to our knowledge system design at multiple levels — from structured document types to crystallisation to link semantics. Vague but persistent.
- [Automated tests for text](./automated-tests-for-text.md) *(note)* — Text artifacts can be tested with the same pyramid as software — deterministic checks, LLM rubrics, corpus compatibility — built from real failures not taxonomy
- [Automating KB learning is an open problem](./automating-kb-learning-is-an-open-problem.md) *(note)* — The KB already learns through manual work (every improvement is capacity change per Simon). The open problem is automating the judgment-heavy mutations — connections, groupings, synthesis — which require oracles we can't yet manufacture.
- [Backlinks — use cases and design space](./backlinks.md) *(note)* — Analysis of where backlinks (inbound link visibility) would concretely help agents working in the KB — use cases, trade-offs, and design options
- [The bitter lesson stops at calculators](./bitter-lesson-boundary.md) *(structured-claim)* — The bitter lesson has a boundary — calculators vs vision features illustrate when exact solutions survive scaling and when they don't
- [Claim notes should use Toulmin-derived sections for structured argument](./claim-notes-should-use-toulmin-derived-sections-for-structured-argument.md) *(structured-claim)* — Three independent threads converged on Toulmin's argument structure — adopting Toulmin sections as base type `structured-claim` separates claim-titled notes (any note) from fully argued claims (the type)
- [Claw design](./claw-design.md) *(index)* — Index of notes about claw architecture, operations, and evaluation — how claws are built, installed, operated, and assessed
- [Claw learning is broader than retrieval](./claw-learning-is-broader-than-retrieval.md) *(note)* — A Claw's learning loop must improve action capacity (classification, planning, communication), not just retrieval — question-answering is one mode among many
- [Commonplace architecture](./commonplace-architecture.md) *(note)* — The commonplace repo's own internal layout — what exists, what's missing, and the decision to put global types in CLAUDE.md instead of kb/types/
- [Commonplace installation architecture](./commonplace-installation-architecture.md) *(note)* — Design for how commonplace installs into a project — two trees (user's kb/ and framework's commonplace/), operational artifacts copied for prompt simplicity, methodology referenced for deeper reasoning
- [Computational model](./computational-model.md) *(index)* — Index of notes applying programming language theory to LLM instructions — scoping, homoiconicity, partial evaluation, typing; the computational model of LLM-based systems viewed through PL concepts
- [CLAUDE.md is a router, not a manual](./context-loading-strategy.md) *(note)* — CLAUDE.md should be a slim router to task-specific docs, not a comprehensive manual — because it's loaded every session
- [Continuous learning is stabilisation during deployment](./continuous-learning-is-stabilisation-during-deployment.md) *(structured-claim)* — AI labs' continuous learning — adapting deployed models without retraining — is achievable through stabilisation with versioned artifacts, which beats weight updates on inspectability, rollback, verification, and composability.
- [Convert still requires semantic description](./convert-still-requires-semantic-description.md)
- [Crystallisation](./crystallisation.md) *(note)* — Definition — crystallisation is the phase transition from natural language instructions to executable code, changing medium, consumer, and verification regime
- [Deep search is connection methodology applied to a temporarily expanded corpus](./deep-search-is-connection-methodology-applied-to-temporarily-expanded-corpus.md) *(note)* — Design exploration for a deep search skill that reuses /connect's dual discovery and articulation testing on web search results, building a temporary research graph before bridging to KB
- [Deploy-time learning: The Missing Middle](./deploy-time-learning-the-missing-middle.md) *(note)* — Deploy-time learning fills the gap between training and in-context — repo artifacts provide durable, inspectable adaptation through three mechanisms (stabilisation, crystallisation, distillation) with a verifiability gradient from prompt tweaks to deterministic code
- [Design methodology — borrow widely, filter by first principles](./design-methodology-borrow-widely-filter-by-first-principles.md) *(note)* — We borrow from any source but adopt based on first-principles support — except programming patterns, which get a fast pass because the bet is that claws are a new kind of software system
- [Deterministic validation should be a script](./deterministic-validation-should-be-a-script.md) *(note)* — Half of /validate's checks are hard-oracle (enums, link resolution, frontmatter structure) and could run as a Python script in milliseconds instead of burning LLM tokens via the skill
- [Directory-scoped types are cheaper than global types](./directory-scoped-types-are-cheaper-than-global-types.md) *(note)* — Global types tax every session's context; directory-scoped types load only when working in that directory — most structural affordances are directory-local, so the type system should match that economy
- [Discovery is seeing the particular as an instance of the general](./discovery-is-seeing-the-particular-as-an-instance-of-the-general.md) *(note)* — Critiques the topic-vs-mechanism linking dichotomy — discovery varies by abstraction depth, not link kind. The hard problem is positing a new general concept and simultaneously recognizing existing particulars as instances of it. Darwin, Fleming, and mathematical lemma extraction share this dual structure.
- [Distillation](./distillation.md) *(note)* — Definition — distillation is the extraction of operational procedures from discursive reasoning, staying in the same medium but changing rhetorical mode from argumentative to procedural
- [Document classification](./document-classification.md) *(spec)* — Taxonomy overview — the base types table and migration from old flat types; global field definitions, status, and traits live in types/note.md
- [Document system](./document-system.md) *(index)* — Index of notes about document types, writing conventions, validation, and structural quality — how notes are classified, structured, and checked
- [Document types should be verifiable](./document-types-should-be-verifiable.md) *(note)* — Document types should assert verifiable structural properties, not subject matter — with a base type + traits model inspired by gradual and structural typing
- [Error correction works with above-chance oracles and decorrelated checks](./error-correction-works-above-chance-oracles-with-decorrelated-checks.md) *(note)* — Error correction for LLM output is viable whenever the oracle has discriminative power (TPR > FPR) and checks are decorrelated — amplification cost scales with 1/(TPR-FPR)² and independence of errors
- [Files beat a database for agent knowledge bases](./files-not-database.md) *(note)* — Files with git beat a database for agent-facing knowledge bases — universal interface, free versioning, no infrastructure to maintain
- [Frontloading spares execution context](./frontloading-spares-execution-context.md) *(note)* — Pre-computing static parts of LLM instructions and inserting results spares execution context — the primary bottleneck in instructing LLMs; the mechanism is partial evaluation applied to instructions with underspecified semantics
- [Generate claw skills at build time, don't parameterise them](./generate-instructions-at-build-time.md) *(note)* — Claw skills should be generated from templates at setup time, not parameterised with runtime variables — applying the general principle that indirection is costly in LLM instructions
- [Human-LLM differences are load-bearing for knowledge system design](./human-llm-differences-are-load-bearing-for-knowledge-system-design.md) *(note)* — Knowledge systems both inherit human-oriented materials and produce dual-audience documents (human + LLM), making human-LLM cognitive differences a first-class design concern rather than a generic disclaimer
- [Human writing structures transfer to LLMs because failure modes overlap](./human-writing-structures-transfer-to-llms-because-failure-modes-overlap.md) *(note)* — Human writing genres evolved to prevent specific reasoning failures; the same structures help LLMs because LLMs exhibit surprisingly human-like failure modes (conflating evidence with opinion, skipping qualifications) — suggesting per-structure transfer evaluation rather than wholesale analogy
- [Indirection is costly in LLM instructions](./indirection-is-costly-in-llm-instructions.md) *(note)* — In code, indirection (variables, config, abstraction layers) is nearly free at runtime — in LLM instructions, every layer of indirection costs context and interpretation overhead on every read
- [Inspectable substrate, not supervision, defeats the blackbox problem](./inspectable-substrate-not-supervision-defeats-the-blackbox-problem.md) *(note)* — Chollet frames agentic coding as ML producing blackbox codebases — crystallisation counters this not by requiring human review but by choosing a substrate (repo artifacts) that any agent can inspect, diff, test, and verify
- [Instructions are typed callables with document type signatures](./instructions-are-typed-callables.md) *(note)* — Skills and tasks are typed callables — they accept document types as input and produce types as output, and should declare their signatures like functions declare parameter types.
- [Learning is capacity change](./learning-is-capacity-change.md) *(note)* — Simon's definition — learning is any change that produces a more or less permanent change in a system's capacity for adapting to its environment. Capacity decomposes into generality and a compound (reliability+speed+cost) that trades against it; three mechanisms (stabilisation, crystallisation, distillation) operate on this trade-off differently.
- [Learning theory](./learning-theory.md) *(index)* — Index of notes about how systems learn, verify, and improve — Simon's capacity framework, stabilisation/crystallisation/distillation mechanisms, oracle theory, and memory architecture
- [Link contracts framework — source material](./link-contracts-framework.md) *(note)* — Reference framework for systematic, testable linking — link contracts, intent taxonomy, automated checks, agent implications
- [Link strength is encoded in position and prose](./link-strength-is-encoded-in-position-and-prose.md) *(note)* — Not all links are equal — inline premise links ("since [X]") carry more weight than footer "related" links. Position and prose encode commitment level, creating a weighted graph that affects traversal, scoring, and quality signals.
- [Links](./links.md) *(index)* — Index of notes about linking — how links work as decision points, navigation modes, link contracts, and automated link management
- [LLM context is a homoiconic medium](./llm-context-is-a-homoiconic-medium.md) *(note)* — LLM context windows are homoiconic — instructions and data share the same representation (natural language tokens), so there is no structural boundary between program and content, producing both the extensibility benefits and the scoping hazards of Lisp, Emacs, and Smalltalk
- [RLM ephemeral code prevents accumulation](./meta/rlm-ephemeral-code-prevents-accumulation.md) — RLM discards generated code after each run — the single design choice that separates it from llm-do
- [Methodology enforcement is stabilisation](./methodology-enforcement-is-stabilisation.md) *(note)* — Instructions, skills, hooks, and scripts form a stabilisation gradient for methodology — from underspecified and indeterministic (LLM interprets and may not follow) to fully deterministic (code always runs), with hooks occupying a middle ground of deterministic triggers with indeterministic responses
- [Needs testing](./needs-testing.md) *(review)* — Promising ideas without enough evidence — extract/connect/review cycle, input classification before processing
- [Notes need quality scores to scale curation](./notes-need-quality-scores-to-scale-curation.md) *(note)* — As the KB grows, /connect will retrieve too many candidates — note quality scores (status, type, inbound links, recency, link strength) filter candidates and prioritise what's worth connecting
- [The bitter lesson boundary is a gradient, not a binary](./oracle-strength-spectrum.md) *(structured-claim)* — The bitter lesson boundary is a gradient — oracle strength (how cheaply and reliably you can verify correctness) determines where a component sits and how to invest engineering effort
- [Programming practices apply to prompting](./programming-practices-apply-to-prompting.md) *(note)* — Programming practices — typing, testing, progressive compilation, version control — apply to LLM prompting and knowledge systems, with semantic underspecification and execution indeterminism making some practices harder in distinct ways
- [Quality signals for KB evaluation](./quality-signals-for-kb-evaluation.md) *(note)* — Catalogues graph-topology, content-proxy, and LLM-hybrid signals that could be combined into a weak composite oracle to drive a mutation-based KB learning loop without requiring usage data.
- [Agent Skills for Context Engineering](./related-systems/agent-skills-for-context-engineering.md) *(note)* — Skill-based context engineering framework — 14 instructional modules covering attention mechanics, multi-agent patterns, memory, evaluation. Strong on operational patterns, weaker on learning theory.
- [Ars Contexta](./related-systems/arscontexta.md) *(note)* — Claude Code plugin that generates knowledge systems from conversation, backed by 249 research claims. Ancestor of our claw — we borrowed link semantics, propositional titles, and three-space architecture, then diverged in theory and structure.
- [ClawVault](./related-systems/clawvault.md) *(note)* — TypeScript memory system for AI agents with scored observations, session handoffs, and reflection pipelines — has a working workshop layer where we have theory, making it the strongest source of borrowable patterns for ephemeral knowledge
- [Related Systems](./related-systems/related-systems-index.md) *(index)* — Comparable knowledge/agent systems tracked for evolving ideas, convergence signals, and borrowable patterns
- [Thalo entity types compared to claw document types](./related-systems/thalo-type-comparison.md) *(note)* — Reference for borrowing recurring note shapes from Thalo — their entity types (opinion, reference, lore, journal, synthesis) map onto our types with concrete gaps still open (supersedes links, source status tracking)
- [Thalo](./related-systems/thalo.md) *(note)* — Custom plain-text language for knowledge management with Tree-Sitter grammar, typed entities, 27 validation rules, and LSP. Makes the same programming-theory-over-psychology bet we do, but went further into formalization with a custom DSL.
- [Eric Evans: AI Components for a Deterministic System](./related_works/evans-ai-components-deterministic-system.md)
- [Granular Software](./related_works/granular-software.md)
- [Professional Software Developers and AI Agent Use](./related_works/professional-developers-ai-agents.md)
- [RLM Implementations vs llm-do](./related_works/rlm-comparison.md)
- [RLM (Recursive Language Model) — For Programmers](./related_works/rlm-explained.md)
- [Shesha vs llm-do](./related_works/shesha-comparison.md)
- [Reliability dimensions map to oracle-hardening stages](./reliability-dimensions-map-to-oracle-hardening-stages.md) *(note)* — The four reliability dimensions from Rabanser et al. (consistency, robustness, predictability, safety) each harden a different oracle question — mapping empirical agent evaluation onto the oracle-strength spectrum
- [Analysis: Adaptation of Agentic AI (arXiv:2512.16301)](./research/adaptation-agentic-ai-analysis.md) — Analysis of agentic AI adaptation paper and llm-do implications
- [What Survives in Multi-Agent Systems](./research/voooooogel-multi-agent-future.md) — Analysis of what multi-agent patterns will survive stronger models
- [Scenario decomposition drives architecture](./scenario-decomposition-drives-architecture.md) *(note)* — Deriving architectural requirements by decomposing concrete user stories into step-by-step context needs — not from abstract read/write operations but from what the agent actually has to load at each stage, in both the commonplace repo and installed projects
- [Scenarios](./scenarios.md) *(note)* — Concrete use cases for the knowledge system — upstream change analysis and proposing our own changes
- [Skills derive from methodology through distillation](./skills-derive-from-methodology-through-distillation.md) *(structured-claim)* — The methodology→skill relationship is distillation (extracting operational procedures from discursive reasoning in the same medium) — distinct from crystallisation (prompt→code phase transition) and stabilisation (narrowing output distribution)
- [Operational signals that a component is a softening candidate](./softening-signals.md)
- [Spec mining is crystallisation's operational mechanism](./spec-mining-as-crystallisation.md)
- [Stabilisation](./stabilisation.md) *(note)* — Definition — stabilisation is any act that narrows the space of valid interpretations an underspecified spec admits, trading generality for gains in reliability, speed, and cost — from same-medium narrowing to full crystallisation (medium change)
- [Stale indexes are worse than no indexes](./stale-indexes-are-worse-than-no-indexes.md) *(note)* — An agent trusts an index as exhaustive — a missing entry doesn't trigger search, it makes the note invisible
- [Storing LLM outputs is stabilization](./storing-llm-outputs-is-stabilization.md) *(note)* — Choosing to keep a specific LLM output resolves semantic underspecification to one interpretation and freezes it against execution indeterminism — the same stabilizing move the parent note describes for code, applied to artifacts
- [Structure activates higher-quality training distributions](./structure-activates-higher-quality-training-distributions.md) *(note)* — Structured templates like Evidence/Reasoning sections steer autoregressive generation toward higher-quality training data (scientific papers, legal analyses) rather than unstructured web text — the structure acts as a distribution selector
- [Structured output is easier for humans to review](./structured-output-is-easier-for-humans-to-review.md) *(note)* — Separated Evidence and Reasoning sections let human reviewers check facts and logic independently — a purely readability argument that doesn't depend on LLM behavior at all
- [Sub-agent context should be lexically scoped by default](./sub-agent-context-should-be-lexically-scoped-by-default.md) *(note)* — Sub-agents should get clean context frames determined by their prompt, not the accumulated conversation history — lexical scope by default, with user preferences and safety policies as explicitly declared dynamic bindings
- [Text testing framework — source material](./text-testing-framework.md) *(note)* — Reference framework for automated text testing — contracts per document type, test pyramid (deterministic/LLM rubric/corpus), production workflow
- [Three-space agent memory maps to Tulving's taxonomy](./three-space-agent-memory-maps-to-tulving-taxonomy.md) — Agent memory split into knowledge, self, and operational spaces mirrors Tulving's semantic/episodic/procedural distinction
- [Three-space memory separation predicts measurable failure modes](./three-space-memory-separation-predicts-measurable-failure-modes.md) — The three-space memory claim is testable because flat memory predicts specific cross-contamination failures
- [Title as claim enables traversal as reasoning](./title-as-claim-enables-traversal-as-reasoning.md) *(note)* — When note titles are claims rather than topics, following links between them reads as a chain of reasoning — the file tree becomes a scan of arguments, and link semantics (since, because, but) encode relationship types
- [Topic links from frontmatter are deterministic](./topic-links-from-frontmatter-are-deterministic.md) *(note)* — The areas-to-Topics mapping is mechanical — now implemented as scripts/sync_topic_links.py
- [Traversal improves the graph](./traversal-improves-the-graph.md) *(note)* — Every traversal is a read-write opportunity — agents should log improvement opportunities during reading, then process them separately to avoid context-switching
- [Two kinds of navigation](./two-kinds-of-navigation.md) *(note)* — Link-following is local with context; search is long-range with titles/descriptions; indexes bridge both modes
- [Type system enforces metadata that navigation depends on](./type-system-enforces-metadata-that-navigation-depends-on.md) *(note)* — Descriptions don't appear spontaneously — they exist because the note base type requires them; without enforcement, metadata degrades and navigation collapses to opening every document
- [{NNN}-{decision-title}](./types/adr.md) *(adr)*
- [{area-name} index](./types/index.md) *(index)*
- [{System name}](./types/related-system.md) *(note)*
- [{Claim as title — an assertion, not a topic label}](./types/structured-claim.md) *(structured-claim)*
- [Types give agents structural hints before opening documents](./types-give-agents-structural-hints-before-opening-documents.md) *(note)* — Types and descriptions let agents make routing decisions without loading full documents — the type says what operations a document affords, the description filters among instances of that type
- [Unified calling conventions enable bidirectional refactoring between neural and symbolic](./unified-calling-conventions-enable-bidirectional-refactoring.md) *(note)* — When agents and tools share a calling convention, components can move between neural and symbolic without changing call sites — llm-do demonstrates this with name-based dispatch over a hybrid VM
- [What cludebot teaches us](./what-cludebot-teaches-us.md) — Techniques from cludebot worth borrowing — what we already cover, what to adopt now, and what to watch for as the KB grows
- [What doesn't work](./what-doesnt-work.md) *(review)* — Anti-patterns and areas with insufficient evidence — auto-commits, queue overhead, validation ceremony, session rhythm
- [What works](./what-works.md) *(review)* — Patterns proven valuable in practice — prose-as-title, template nudges, frontmatter queries, semantic search via qmd, discovery-first, public/internal boundary
- [Why directories despite their costs](./why-directories-despite-their-costs.md) *(note)* — Directories buy one–two orders of magnitude of human-navigable scale over flat files, and enable local conventions per subsystem — but each new directory taxes routing, search config, skills, and cross-directory linking
- [Why notes have types](./why-notes-have-types.md) *(note)* — Six roles of the type system — navigation hints, metadata enforcement, verifiable structure, local extensibility, output quality through structured writing discipline, and maturation through stabilisation
- [The wikiwiki principle: lowest-friction capture, then progressive refinement in place](./wikiwiki-principle-lowest-friction-capture-then-progressive-refinement.md) *(note)* — Ward Cunningham's wiki design principle — minimize capture friction, then refine in place — is the animating idea behind the text→note→structured-claim crystallisation ladder
