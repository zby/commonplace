{
  "source": "https://x.com/koylanai/status/2025286163641118915",
  "captured": "2026-02-22T11:51:03.499122+00:00",
  "type": "x-article",
  "status_id": "2025286163641118915",
  "conversation_id": "2025286163641118915",
  "target_post": {
    "article": {
      "media_entities": [
        "3_2025256717408223233",
        "3_2025266558931525632",
        "3_2025256255552356352",
        "3_2025267841843249152",
        "3_2025260062810238976",
        "3_2025260657709400064",
        "3_2025259682101702657",
        "3_2025257778005069824",
        "3_2025265634762731520",
        "3_2025258736168660992",
        "3_2025266035327197184"
      ],
      "title": "The File System Is the New Database: How I Built a Personal OS for AI Agents",
      "entities": {
        "tweets": [
          {
            "id": "1996905189656211931"
          },
          {
            "id": "2008824728824451098"
          },
          {
            "id": "1998530190847390025"
          },
          {
            "id": "2023405681080938932"
          },
          {
            "id": "1996757974610559171"
          },
          {
            "id": "2005082048973905938"
          },
          {
            "id": "1975090268316827983"
          },
          {
            "id": "1997444237890081104"
          },
          {
            "id": "2016684758588154239"
          },
          {
            "id": "2018865011356053927"
          },
          {
            "id": "2002797649842331919"
          },
          {
            "id": "2005827257458131321"
          },
          {
            "id": "1987254288393916571"
          },
          {
            "id": "1999192104850133146"
          }
        ],
        "urls": [
          {
            "text": "SKILL.md"
          },
          {
            "text": "CONTENT.md"
          },
          {
            "text": "OPERATIONS.md"
          },
          {
            "text": "NETWORK.md"
          },
          {
            "text": "CLAUDE.md"
          },
          {
            "text": "AGENT.md"
          },
          {
            "text": "AGENT.md"
          },
          {
            "text": "OPERATIONS.md"
          },
          {
            "text": "Sully.ai"
          },
          {
            "text": "todos.md"
          },
          {
            "text": "todos.md"
          },
          {
            "text": "tone-of-voice.md"
          },
          {
            "text": "Sully.ai"
          },
          {
            "text": "https://github.com/muratcankoylan/Agent-Skills-for-Context-Engineering"
          }
        ]
      },
      "cover_media": "3_2025270258316005376",
      "preview_text": "Every AI conversation starts the same way. You explain who you are. You explain what you're working on. You paste in your style guide. You re-describe your goals. You give the same context you gave",
      "plain_text": "Every AI conversation starts the same way. You explain who you are. You explain what you're working on. You paste in your style guide. You re-describe your goals. You give the same context you gave yesterday, and the day before, and the day before that. Then, 40 minutes in, the model forgets your voice and starts writing like a press release.\nI got tired of this. So I built a system to fix it.\nI call it Personal Brain OS. It's a file-based personal operating system that lives inside a Git repository. Clone it, open it in Cursor or Claude Code, and the AI assistant has everything: my voice, my brand, my goals, my contacts, my content pipeline, my research, my failures. No database, no API keys, no build step. Just 80+ files in markdown, YAML, and JSONL that both humans and language models read natively.\n \nI'm sharing the full architecture, the design decisions, and the mistakes so you can build your own version. Not a copy of mine; yours. The specific modules, the file schemas, the skill definitions will look different for your work. But the patterns transfer. The principles for structuring information for AI agents are universal. Take what fits, ignore what doesn't, and ship something that makes your AI actually useful instead of generically helpful.\nHere's how I built it, why the architecture decisions matter, and what I learned the hard way.\n \n1) THE CORE PROBLEM: CONTEXT, NOT PROMPTS\nMost people think the bottleneck with AI assistants is prompting. Write a better prompt, get a better answer. That's true for single interactions and production agent prompts. It falls apart when you want an AI to operate as you across dozens of tasks over weeks and months.\nThe Attention Budget: Language models have a finite context window, and not all of it is created equal. This means dumping everything you know into a system prompt isn't just wasteful, it actively degrades performance. Every token you add competes for the model's attention. \n \nOur brains work similarly. When someone briefs you for 15 minutes before a meeting, you remember the first thing they said and the last thing they said. The middle blurs. Language models have the same U-shaped attention curve, except theirs is mathematically measurable. Token position affects recall probability. The newer models are getting better at this, but still, you are distracting the model from focusing on what matters most. Knowing this changes how you design information architecture for AI systems. \n \nInstead of writing one massive system prompt, I split Personal OS into 11 isolated modules. When I ask the AI to write a blog post, it loads my voice guide and brand files. When I ask it to prepare for a meeting, it loads my contact database and interaction history. The model never sees network data during a content task, and never sees content templates during a meeting prep task.\n \nProgressive Disclosure: This is the architectural pattern that makes the whole system work. Instead of loading all 80+ files at once, the system uses three levels. Level 1 is a lightweight routing file that's always loaded. It tells the AI which module is relevant. Level 2 is module-specific instructions that load only when that module is needed. Level 3 is the actual data JSONL logs, YAML configs, research documents, loaded only when the task requires them. \nThis mirrors how experts operate. The three levels create a funnel: broad routing, then module context, then specific data. At each step, the model has exactly what it needs and nothing more. \n \nMy routing file is `SKILL.md` that tells the agent \"this is a content task, load the brand module\" or \"this is a network task, load the contacts.\" The module instruction files (`CONTENT.md`, `OPERATIONS.md`, `NETWORK.md`) are 40-100 lines each, with file inventories, workflow sequences, and an `<instructions>` block with behavioural rules for that domain. Data files load last, only when needed. The AI reads contacts line by line from JSONL rather than parsing the entire file. Three levels, with a maximum of two hops to any piece of information.\n \nThe Agent Instruction Hierarchy: I built three layers of instructions that scope how the AI behaves at different levels. At the repository level, `CLAUDE.md` is the onboarding document -- every AI tool reads it first and gets the full map of the project. At the brain level, `AGENT.md` contains seven core rules and a decision table that maps common requests to exact action sequences. At the module level, each directory has its own instruction file with domain-specific behavioral constraints. \n \nThis solves the \"conflicting instructions\" problem that plagues large AI projects. When everything lives in one system prompt, rules contradict each other. A content creation instruction might conflict with a networking instruction. By scoping rules to their domain, you eliminate conflicts and give the agent clear, non-overlapping guidance. The hierarchy also means you can update one module's rules without risking regression in another module's behavior. \n \nMy `AGENT.md` is a decision table. The AI reads \"User says 'send email to Z'\" and immediately sees: \nStep 1, look up contact in HubSpot. \nStep 2, verify email address. \nStep 3, send via Gmail. \nModule-level files like `OPERATIONS.md` define priority levels (P0: do today, P1: this week, P2: this month, P3: backlog) so the agent triages tasks consistently. The agent follows the same priority system I use because the system is codified, not implied.\n \n2) THE FILE SYSTEM AS MEMORY\nOne of the most counterintuitive decisions I made: no database. No vector store. No retrieval system except Cursor or Claude Code's features. Just files on disk, versioned with Git.\n \nFormat-Function Mapping: Every file format in the system was chosen for a specific reason related to how AI agents process information. JSONL for logs because it's append-only by design, stream-friendly (the agent reads line by line without parsing the entire file), and every line is self-contained valid JSON. YAML for configuration because it handles hierarchical data cleanly, supports comments, and is readable by both humans and machines without the noise of JSON brackets. Markdown for narrative because LLMs read it natively, it renders everywhere, and it produces clean diffs in Git. \n \nJSONL's append-only nature prevents a category of bugs where an agent accidentally overwrites historical data. I've seen this happen with JSON files agent writes the whole file, loses three months of contact history. With JSONL, the agent can only add lines. Deletion is done by marking entries as `\"status\": \"archived\"`, which preserves the full history for pattern analysis. YAML's comment support means I can annotate my goals file with context the agent reads but that doesn't pollute the data structure. And Markdown's universal rendering means my voice guide looks the same in Cursor, on GitHub, and in any browser. \n \nMy system uses 11 JSONL files (posts, contacts, interactions, bookmarks, ideas, metrics, experiences, decisions, failures, engagement, meetings), 6 YAML files (goals, values, learning, circles, rhythms, heuristics), and 50+ Markdown files (voice guides, research, templates, drafts, todos). Every JSONL file starts with a schema line: `{\"_schema\": \"contact\", \"_version\": \"1.0\", \"_description\": \"...\"}`. The agent always knows the structure before reading the data.\n \nEpisodic Memory: Most \"second brain\" systems store facts. Mine stores judgment as well. The `memory/` module contains three append-only logs: `experiences.jsonl` (key moments with emotional weight scores from 1-10), `decisions.jsonl` (key decisions with reasoning, alternatives considered, and outcomes tracked), and `failures.jsonl` (what went wrong, root cause, and prevention steps). \n \nThere's a difference between an AI that has your files and an AI that has your judgment. Facts tell the agent what happened. Episodic memory tells the agent what mattered, what I'd do differently, and how I think about tradeoffs. When the agent encounters a decision similar to one I've logged, it can reference my past reasoning instead of generating generic advice. The failures log is the most valuable, it encodes pattern recognition that took real pain to acquire. \nWhen I was deciding whether to accept Antler Canada's $250K investment or join Sully.ai as Context Engineer, the decision log captured both options, the reasoning for each, and the outcome. If a similar career tradeoff comes up, the agent doesn't give me generic career advice. It references how I actually think about these decisions: \"Learning > Impact > Revenue > Growth\" is my priority order, and \"Can I touch everything? Will I learn at the edge of my capability? Do I respect the founders?\" is my company-joining framework.\nCross-Module References: The system uses a flat-file relational model. No database, but structured enough for agents to join data across files. `contact_id` in `interactions.jsonl` points to entries in `contacts.jsonl`. `pillar` in `ideas.jsonl` maps to content pillars defined in `identity/brand.md`. Bookmarks feed content ideas. Post metrics feed weekly reviews. The modules are isolated for loading, but connected for reasoning.\nIsolation without connection is just a pile of folders. The cross-references let the agent traverse the knowledge graph when needed. \"Prepare for my meeting with Sarah\" triggers a lookup chain: find Sarah in contacts, pull her interactions, check pending todos involving her, compile a brief. The agent follows the references across modules without loading the entire system. \nMy pre-meeting workflow chains three files: `contacts.jsonl` (who they are), `interactions.jsonl` (filtered by contact_id for history), and `todos.md` (any pending items). The agent produces a one-page brief with relationship context, last conversation summary, and open follow-ups. No manual assembly. The data structure makes the workflow possible.\n \n3) THE SKILL SYSTEM: TEACHING AI HOW TO DO YOUR WORK\nFiles store knowledge. Skills encode process. I built Agent Skills following the Anthropic Agent Skills standard, structured instructions that tell the AI how to perform specific tasks with quality gates baked in.\n \nAuto-Loading vs. Manual Invocation: Two types of skills solve two different problems. Reference skills (`voice-guide`, `writing-anti-patterns`) set `user-invocable: false` in their YAML frontmatter. The agent reads the description field and injects them automatically whenever the task involves writing. I never invoke them, they activate silently, every time. Task skills (`/write-blog`, `/topic-research`, `/content-workflow`) set `disable-model-invocation: true`. The agent can't trigger them on its own. I type the slash command, and the skill becomes the agent's complete instruction set for that task. \n \nAuto-loading solves the consistency problem. I don't have to remember to say \"use my voice\" every time I ask for a draft. The system remembers for me. Manual invocation solves the precision problem. A research task has different quality gates than a blog post. Keeping them separate prevents the agent from conflating two different workflows. The YAML frontmatter is the mechanism, and a few metadata fields control the entire loading behaviour. \n \nWhen I type `/write-blog context engineering for marketing teams`, five things happen automatically: the voice guide loads (how I write), the anti-patterns load (what I never write), the blog template loads (7-section structure with word count targets), the persona folder is checked for audience profiles, and the research folder is checked for existing topic research. One slash command triggers a full context assembly. The skill file itself says \"Read `brand/tone-of-voice.md`\", it references the source module, never duplicates the content. Single source of truth.\n \nThe Voice System: My voice is encoded as structured data and ngl with some vibes. The voice profile rates five attributes on a 1-10 scale: Formal/Casual (6), Serious/Playful (4), Technical/Simple (7), Reserved/Expressive (6), Humble/Confident (7). The anti-patterns file contains 50+ banned words across three tiers, banned openings, structural traps (forced rule of three, copula avoidance, excessive hedging), and a hard limit of one em-dash per paragraph. \n \nMost people describe their voice with adjectives: \"professional but approachable.\" That's useless for an AI. A 7 on the Technical/Simple scale tells the model exactly where to land. The banned word list is even more powerful; it's easier to define what you're NOT than what you are. The agent checks every draft against the anti-patterns list and rewrites anything that triggers it. The result is content that sounds like me because the guardrails prevent it from sounding like AI. \nEvery content template includes voice checkpoints every 500 words: \"Am I leading with insight? Am I being specific with numbers? Would I actually post this?\" The blog template has a 4-pass editing process built in: structure edit (does the hook grab?), voice edit (banned words scan, sentence rhythm check), evidence edit (claims sourced?), and a read-aloud test. The quality gates are part of the skill, not something I add after the fact.\n \nTemplates as Structured Scaffolds: Five content templates define the structure for different content types. The long-form blog template has seven sections (Hook, Core Concept, Framework, Practical Application, Failure Modes, Getting Started, Closing) with word count targets per section totaling 2,000-3,500 words. The thread template defines an 11-post structure with a hook, deep-dive, results, and CTA. The research template has four phases: landscape mapping, technical deep-dive, evidence collection, and gap analysis. \nTemplates not only constrain creativity but also constrain chaos. Without structure, the agent produces amorphous blobs of text. With structure, it produces content that has rhythm, progression, and payoff. Each template also includes a quality checklist so the agent can self-evaluate before presenting the draft. \nThe research template outputs to `knowledge/research/[topic].md` with a structured format: Executive Summary, Landscape Map, Core Concepts, Evidence Bank (with statistics, quotes, case studies, and papers each cited with source and date), Failure Modes, Content Opportunities, and a Sources List graded HIGH/MEDIUM/LOW on reliability. That research document then feeds into the blog template's outline stage. The output of one skill becomes the input of the next. The pipeline builds on itself.\n \n4) THE OPERATING SYSTEM: HOW I ACTUALLY USE THIS DAILY\nArchitecture is nothing without execution. \nHere's how the system runs in practice.\nThe Content Pipeline: Seven stages: Idea, Research, Outline, Draft, Edit, Publish, Promote. \nIdeas are captured to `ideas.jsonl` with a scoring system, each idea rated 1-5 on alignment with positioning, unique insight, audience need, timeliness, and effort-versus-impact. Proceed if total score hits 15 or higher. \nResearch outputs to the knowledge module. \nDrafts go through four editing passes. \nPublished content gets logged to `posts.jsonl` with platform, URL, and engagement metrics. \nPromotion uses the thread template to create an X announcement and a LinkedIn adaptation. \n \nI batch content creation on Sundays: 3-4 hours, target output of 3-4 posts drafted and outlined. The content calendar maps each day to a platform and content type.\nThe Personal CRM: Contacts organized into four circles with different maintenance cadences: inner (weekly), active (bi-weekly), network (monthly), dormant (quarterly reactivation). Each contact record has `can_help_with` and `you_can_help_with` fields that enable the introduction matching system. cross-referencing these fields surfaces mutually valuable intros. Interactions are logged with sentiment tracking (positive, neutral, needs_attention) so relationship health is visible at a glance. \n \nMost people keep contacts in their head and let relationships decay through neglect. The `stale_contacts` script cross-references contacts (who they are), interactions (when we last talked), and circles (how often we should talk) to surface outreach needs. A 30-second scan each week shows me which relationships need attention. \nSpecialized groups in `circles.yaml`founders, investors, ai_builders, creators, mentors, mentees, each have explicit relationship development strategies. For AI builders: share useful content, collaborate on open source, provide tool feedback, amplify their work. For mentors: bring specific questions, update on progress from previous advice, look for ways to add value back. These are operational instructions the agent follows when I ask \"Who should I reach out to this week?\"\nAutomation Chains: Five scripts handle recurring workflows. They chain together for compound operations. The Sunday weekly review runs three scripts in sequence: `metrics_snapshot.py` updates the numbers, `stale_contacts.py` flags relationships, `weekly_review.py` generates a summary document with completed-versus-planned, metrics trends, and next week's priorities. The content ideation chain reads recent bookmarks, checks undeveloped ideas, generates fresh suggestions, and cross-references with the content calendar to find scheduling gaps. These aren't cron jobs -- the agent runs them when I ask for a review, or I trigger them with `npm run weekly-review`. \n \nScripts that output to stdout in agent-readable format close the loop between data and action. The weekly review script doesn't just tell me what happened -- it references my goals and identifies which key results are on track, which are behind, and what to prioritize next week. The scripts read from the same files the agent reads during normal operation, so there's no data duplication or synchronization problem. \n \nAfter running the weekly review, the agent has everything it needs to update `todos.md` for next week, adjust `goals.yaml` progress numbers, and suggest content topics that align with underperforming key results. The review isn't a report -- it's the starting point for next week's planning. The automation creates a feedback loop: goals drive content, content drives metrics, metrics drive reviews, reviews drive goals.\n \n5) WHAT I GOT WRONG AND WHAT I'D DO DIFFERENTLY\nI over-engineered the schema first pass. My initial JSONL schemas had 15+ fields per entry. Most were empty. Agents struggle with sparse data -- they try to fill in fields or comment on the absence. I cut schemas to 8-10 essential fields and added optional fields only when I actually had data for them. Simpler schemas, better agent behavior.\nThe voice guide was too long at first. Version one of `tone-of-voice.md` was 1,200 lines. The agent would start strong, then drift by paragraph four as the voice instructions fell into the lost-in-middle zone. I restructured it to front-load the most distinctive patterns (signature phrases, banned words, opening patterns) in the first 100 lines, with extended examples further down. The critical rules need to be at the top, not the middle.\nModule boundaries matter more than you think. I initially had identity and brand in one module. The agent would load my entire bio when it only needed my banned words list. Splitting them into two modules cut token usage for voice-only tasks by 40%. Every module boundary is a loading decision. Get them wrong and you load too much or too little.\nAppend-only is non-negotiable. I lost three months of post engagement data early on because an agent rewrote `posts.jsonl` instead of appending to it. JSONL's append-only pattern isn't just a convention -- it's a safety mechanism. The agent can add data. It cannot destroy data. This is the most important architectural decision in the system.\n \n6) THE RESULTS AND THE PRINCIPLE BEHIND THEM\nThe real result is simpler than any metric. I open Cursor or Claude Code, start a conversation, and the AI already knows who I am, how I write, what I'm working on, and what I care about. It writes in my voice because my voice is encoded as structured data. It follows my priorities because my goals are in a YAML file it reads before suggesting what to work on. It manages my relationships because my contacts and interactions are in files it can query.\nThe principle behind all of it: this is context engineering, not prompt engineering. Prompt engineering asks \"how do I phrase this question better?\" Context engineering asks \"what information does this AI need to make the right decision, and how do I structure that information so the model actually uses it?\"\nThe shift is from optimizing individual interactions to designing information architecture. It's the difference between writing a good email and building a good filing system. One helps you once. The other helps you every time.\n \nThe entire system fits in a Git repository. Clone it to any machine, point any AI tool at it, and the operating system is running. Zero dependencies. Full portability. And because it's Git, every change is versioned, every decision is traceable, and nothing is ever truly lost.\n \nMuratcan Koylan is Context Engineer at Sully.ai, where he designs context engineering systems for healthcare AI. His on-source work on context engineering (8,000+ GitHub stars) is cited in academic research alongside Anthropic. Previously AI Agent Systems Manager at 99Ravens AI, building multi-agent systems handling 10,000+ weekly interactions.\nFramework: [Agent Skills for Context Engineering](https://github.com/muratcankoylan/Agent-Skills-for-Context-Engineering)\n \n"
    },
    "author_id": "1603551009854423040",
    "text": "https://t.co/7kZ0k7nbxI",
    "conversation_id": "2025286163641118915",
    "created_at": "2026-02-21T19:07:04.000Z",
    "edit_history_tweet_ids": [
      "2025286163641118915"
    ],
    "id": "2025286163641118915",
    "entities": {
      "urls": [
        {
          "start": 0,
          "end": 23,
          "url": "https://t.co/7kZ0k7nbxI",
          "expanded_url": "http://x.com/i/article/2025249985722224640",
          "display_url": "x.com/i/article/2025\u2026",
          "status": 500,
          "unwound_url": "https://x.com/i/article/2025249985722224640"
        }
      ]
    }
  },
  "posts": [
    {
      "article": {
        "media_entities": [
          "3_2025256717408223233",
          "3_2025266558931525632",
          "3_2025256255552356352",
          "3_2025267841843249152",
          "3_2025260062810238976",
          "3_2025260657709400064",
          "3_2025259682101702657",
          "3_2025257778005069824",
          "3_2025265634762731520",
          "3_2025258736168660992",
          "3_2025266035327197184"
        ],
        "title": "The File System Is the New Database: How I Built a Personal OS for AI Agents",
        "entities": {
          "tweets": [
            {
              "id": "1996905189656211931"
            },
            {
              "id": "2008824728824451098"
            },
            {
              "id": "1998530190847390025"
            },
            {
              "id": "2023405681080938932"
            },
            {
              "id": "1996757974610559171"
            },
            {
              "id": "2005082048973905938"
            },
            {
              "id": "1975090268316827983"
            },
            {
              "id": "1997444237890081104"
            },
            {
              "id": "2016684758588154239"
            },
            {
              "id": "2018865011356053927"
            },
            {
              "id": "2002797649842331919"
            },
            {
              "id": "2005827257458131321"
            },
            {
              "id": "1987254288393916571"
            },
            {
              "id": "1999192104850133146"
            }
          ],
          "urls": [
            {
              "text": "SKILL.md"
            },
            {
              "text": "CONTENT.md"
            },
            {
              "text": "OPERATIONS.md"
            },
            {
              "text": "NETWORK.md"
            },
            {
              "text": "CLAUDE.md"
            },
            {
              "text": "AGENT.md"
            },
            {
              "text": "AGENT.md"
            },
            {
              "text": "OPERATIONS.md"
            },
            {
              "text": "Sully.ai"
            },
            {
              "text": "todos.md"
            },
            {
              "text": "todos.md"
            },
            {
              "text": "tone-of-voice.md"
            },
            {
              "text": "Sully.ai"
            },
            {
              "text": "https://github.com/muratcankoylan/Agent-Skills-for-Context-Engineering"
            }
          ]
        },
        "cover_media": "3_2025270258316005376",
        "preview_text": "Every AI conversation starts the same way. You explain who you are. You explain what you're working on. You paste in your style guide. You re-describe your goals. You give the same context you gave",
        "plain_text": "Every AI conversation starts the same way. You explain who you are. You explain what you're working on. You paste in your style guide. You re-describe your goals. You give the same context you gave yesterday, and the day before, and the day before that. Then, 40 minutes in, the model forgets your voice and starts writing like a press release.\nI got tired of this. So I built a system to fix it.\nI call it Personal Brain OS. It's a file-based personal operating system that lives inside a Git repository. Clone it, open it in Cursor or Claude Code, and the AI assistant has everything: my voice, my brand, my goals, my contacts, my content pipeline, my research, my failures. No database, no API keys, no build step. Just 80+ files in markdown, YAML, and JSONL that both humans and language models read natively.\n \nI'm sharing the full architecture, the design decisions, and the mistakes so you can build your own version. Not a copy of mine; yours. The specific modules, the file schemas, the skill definitions will look different for your work. But the patterns transfer. The principles for structuring information for AI agents are universal. Take what fits, ignore what doesn't, and ship something that makes your AI actually useful instead of generically helpful.\nHere's how I built it, why the architecture decisions matter, and what I learned the hard way.\n \n1) THE CORE PROBLEM: CONTEXT, NOT PROMPTS\nMost people think the bottleneck with AI assistants is prompting. Write a better prompt, get a better answer. That's true for single interactions and production agent prompts. It falls apart when you want an AI to operate as you across dozens of tasks over weeks and months.\nThe Attention Budget: Language models have a finite context window, and not all of it is created equal. This means dumping everything you know into a system prompt isn't just wasteful, it actively degrades performance. Every token you add competes for the model's attention. \n \nOur brains work similarly. When someone briefs you for 15 minutes before a meeting, you remember the first thing they said and the last thing they said. The middle blurs. Language models have the same U-shaped attention curve, except theirs is mathematically measurable. Token position affects recall probability. The newer models are getting better at this, but still, you are distracting the model from focusing on what matters most. Knowing this changes how you design information architecture for AI systems. \n \nInstead of writing one massive system prompt, I split Personal OS into 11 isolated modules. When I ask the AI to write a blog post, it loads my voice guide and brand files. When I ask it to prepare for a meeting, it loads my contact database and interaction history. The model never sees network data during a content task, and never sees content templates during a meeting prep task.\n \nProgressive Disclosure: This is the architectural pattern that makes the whole system work. Instead of loading all 80+ files at once, the system uses three levels. Level 1 is a lightweight routing file that's always loaded. It tells the AI which module is relevant. Level 2 is module-specific instructions that load only when that module is needed. Level 3 is the actual data JSONL logs, YAML configs, research documents, loaded only when the task requires them. \nThis mirrors how experts operate. The three levels create a funnel: broad routing, then module context, then specific data. At each step, the model has exactly what it needs and nothing more. \n \nMy routing file is `SKILL.md` that tells the agent \"this is a content task, load the brand module\" or \"this is a network task, load the contacts.\" The module instruction files (`CONTENT.md`, `OPERATIONS.md`, `NETWORK.md`) are 40-100 lines each, with file inventories, workflow sequences, and an `<instructions>` block with behavioural rules for that domain. Data files load last, only when needed. The AI reads contacts line by line from JSONL rather than parsing the entire file. Three levels, with a maximum of two hops to any piece of information.\n \nThe Agent Instruction Hierarchy: I built three layers of instructions that scope how the AI behaves at different levels. At the repository level, `CLAUDE.md` is the onboarding document -- every AI tool reads it first and gets the full map of the project. At the brain level, `AGENT.md` contains seven core rules and a decision table that maps common requests to exact action sequences. At the module level, each directory has its own instruction file with domain-specific behavioral constraints. \n \nThis solves the \"conflicting instructions\" problem that plagues large AI projects. When everything lives in one system prompt, rules contradict each other. A content creation instruction might conflict with a networking instruction. By scoping rules to their domain, you eliminate conflicts and give the agent clear, non-overlapping guidance. The hierarchy also means you can update one module's rules without risking regression in another module's behavior. \n \nMy `AGENT.md` is a decision table. The AI reads \"User says 'send email to Z'\" and immediately sees: \nStep 1, look up contact in HubSpot. \nStep 2, verify email address. \nStep 3, send via Gmail. \nModule-level files like `OPERATIONS.md` define priority levels (P0: do today, P1: this week, P2: this month, P3: backlog) so the agent triages tasks consistently. The agent follows the same priority system I use because the system is codified, not implied.\n \n2) THE FILE SYSTEM AS MEMORY\nOne of the most counterintuitive decisions I made: no database. No vector store. No retrieval system except Cursor or Claude Code's features. Just files on disk, versioned with Git.\n \nFormat-Function Mapping: Every file format in the system was chosen for a specific reason related to how AI agents process information. JSONL for logs because it's append-only by design, stream-friendly (the agent reads line by line without parsing the entire file), and every line is self-contained valid JSON. YAML for configuration because it handles hierarchical data cleanly, supports comments, and is readable by both humans and machines without the noise of JSON brackets. Markdown for narrative because LLMs read it natively, it renders everywhere, and it produces clean diffs in Git. \n \nJSONL's append-only nature prevents a category of bugs where an agent accidentally overwrites historical data. I've seen this happen with JSON files agent writes the whole file, loses three months of contact history. With JSONL, the agent can only add lines. Deletion is done by marking entries as `\"status\": \"archived\"`, which preserves the full history for pattern analysis. YAML's comment support means I can annotate my goals file with context the agent reads but that doesn't pollute the data structure. And Markdown's universal rendering means my voice guide looks the same in Cursor, on GitHub, and in any browser. \n \nMy system uses 11 JSONL files (posts, contacts, interactions, bookmarks, ideas, metrics, experiences, decisions, failures, engagement, meetings), 6 YAML files (goals, values, learning, circles, rhythms, heuristics), and 50+ Markdown files (voice guides, research, templates, drafts, todos). Every JSONL file starts with a schema line: `{\"_schema\": \"contact\", \"_version\": \"1.0\", \"_description\": \"...\"}`. The agent always knows the structure before reading the data.\n \nEpisodic Memory: Most \"second brain\" systems store facts. Mine stores judgment as well. The `memory/` module contains three append-only logs: `experiences.jsonl` (key moments with emotional weight scores from 1-10), `decisions.jsonl` (key decisions with reasoning, alternatives considered, and outcomes tracked), and `failures.jsonl` (what went wrong, root cause, and prevention steps). \n \nThere's a difference between an AI that has your files and an AI that has your judgment. Facts tell the agent what happened. Episodic memory tells the agent what mattered, what I'd do differently, and how I think about tradeoffs. When the agent encounters a decision similar to one I've logged, it can reference my past reasoning instead of generating generic advice. The failures log is the most valuable, it encodes pattern recognition that took real pain to acquire. \nWhen I was deciding whether to accept Antler Canada's $250K investment or join Sully.ai as Context Engineer, the decision log captured both options, the reasoning for each, and the outcome. If a similar career tradeoff comes up, the agent doesn't give me generic career advice. It references how I actually think about these decisions: \"Learning > Impact > Revenue > Growth\" is my priority order, and \"Can I touch everything? Will I learn at the edge of my capability? Do I respect the founders?\" is my company-joining framework.\nCross-Module References: The system uses a flat-file relational model. No database, but structured enough for agents to join data across files. `contact_id` in `interactions.jsonl` points to entries in `contacts.jsonl`. `pillar` in `ideas.jsonl` maps to content pillars defined in `identity/brand.md`. Bookmarks feed content ideas. Post metrics feed weekly reviews. The modules are isolated for loading, but connected for reasoning.\nIsolation without connection is just a pile of folders. The cross-references let the agent traverse the knowledge graph when needed. \"Prepare for my meeting with Sarah\" triggers a lookup chain: find Sarah in contacts, pull her interactions, check pending todos involving her, compile a brief. The agent follows the references across modules without loading the entire system. \nMy pre-meeting workflow chains three files: `contacts.jsonl` (who they are), `interactions.jsonl` (filtered by contact_id for history), and `todos.md` (any pending items). The agent produces a one-page brief with relationship context, last conversation summary, and open follow-ups. No manual assembly. The data structure makes the workflow possible.\n \n3) THE SKILL SYSTEM: TEACHING AI HOW TO DO YOUR WORK\nFiles store knowledge. Skills encode process. I built Agent Skills following the Anthropic Agent Skills standard, structured instructions that tell the AI how to perform specific tasks with quality gates baked in.\n \nAuto-Loading vs. Manual Invocation: Two types of skills solve two different problems. Reference skills (`voice-guide`, `writing-anti-patterns`) set `user-invocable: false` in their YAML frontmatter. The agent reads the description field and injects them automatically whenever the task involves writing. I never invoke them, they activate silently, every time. Task skills (`/write-blog`, `/topic-research`, `/content-workflow`) set `disable-model-invocation: true`. The agent can't trigger them on its own. I type the slash command, and the skill becomes the agent's complete instruction set for that task. \n \nAuto-loading solves the consistency problem. I don't have to remember to say \"use my voice\" every time I ask for a draft. The system remembers for me. Manual invocation solves the precision problem. A research task has different quality gates than a blog post. Keeping them separate prevents the agent from conflating two different workflows. The YAML frontmatter is the mechanism, and a few metadata fields control the entire loading behaviour. \n \nWhen I type `/write-blog context engineering for marketing teams`, five things happen automatically: the voice guide loads (how I write), the anti-patterns load (what I never write), the blog template loads (7-section structure with word count targets), the persona folder is checked for audience profiles, and the research folder is checked for existing topic research. One slash command triggers a full context assembly. The skill file itself says \"Read `brand/tone-of-voice.md`\", it references the source module, never duplicates the content. Single source of truth.\n \nThe Voice System: My voice is encoded as structured data and ngl with some vibes. The voice profile rates five attributes on a 1-10 scale: Formal/Casual (6), Serious/Playful (4), Technical/Simple (7), Reserved/Expressive (6), Humble/Confident (7). The anti-patterns file contains 50+ banned words across three tiers, banned openings, structural traps (forced rule of three, copula avoidance, excessive hedging), and a hard limit of one em-dash per paragraph. \n \nMost people describe their voice with adjectives: \"professional but approachable.\" That's useless for an AI. A 7 on the Technical/Simple scale tells the model exactly where to land. The banned word list is even more powerful; it's easier to define what you're NOT than what you are. The agent checks every draft against the anti-patterns list and rewrites anything that triggers it. The result is content that sounds like me because the guardrails prevent it from sounding like AI. \nEvery content template includes voice checkpoints every 500 words: \"Am I leading with insight? Am I being specific with numbers? Would I actually post this?\" The blog template has a 4-pass editing process built in: structure edit (does the hook grab?), voice edit (banned words scan, sentence rhythm check), evidence edit (claims sourced?), and a read-aloud test. The quality gates are part of the skill, not something I add after the fact.\n \nTemplates as Structured Scaffolds: Five content templates define the structure for different content types. The long-form blog template has seven sections (Hook, Core Concept, Framework, Practical Application, Failure Modes, Getting Started, Closing) with word count targets per section totaling 2,000-3,500 words. The thread template defines an 11-post structure with a hook, deep-dive, results, and CTA. The research template has four phases: landscape mapping, technical deep-dive, evidence collection, and gap analysis. \nTemplates not only constrain creativity but also constrain chaos. Without structure, the agent produces amorphous blobs of text. With structure, it produces content that has rhythm, progression, and payoff. Each template also includes a quality checklist so the agent can self-evaluate before presenting the draft. \nThe research template outputs to `knowledge/research/[topic].md` with a structured format: Executive Summary, Landscape Map, Core Concepts, Evidence Bank (with statistics, quotes, case studies, and papers each cited with source and date), Failure Modes, Content Opportunities, and a Sources List graded HIGH/MEDIUM/LOW on reliability. That research document then feeds into the blog template's outline stage. The output of one skill becomes the input of the next. The pipeline builds on itself.\n \n4) THE OPERATING SYSTEM: HOW I ACTUALLY USE THIS DAILY\nArchitecture is nothing without execution. \nHere's how the system runs in practice.\nThe Content Pipeline: Seven stages: Idea, Research, Outline, Draft, Edit, Publish, Promote. \nIdeas are captured to `ideas.jsonl` with a scoring system, each idea rated 1-5 on alignment with positioning, unique insight, audience need, timeliness, and effort-versus-impact. Proceed if total score hits 15 or higher. \nResearch outputs to the knowledge module. \nDrafts go through four editing passes. \nPublished content gets logged to `posts.jsonl` with platform, URL, and engagement metrics. \nPromotion uses the thread template to create an X announcement and a LinkedIn adaptation. \n \nI batch content creation on Sundays: 3-4 hours, target output of 3-4 posts drafted and outlined. The content calendar maps each day to a platform and content type.\nThe Personal CRM: Contacts organized into four circles with different maintenance cadences: inner (weekly), active (bi-weekly), network (monthly), dormant (quarterly reactivation). Each contact record has `can_help_with` and `you_can_help_with` fields that enable the introduction matching system. cross-referencing these fields surfaces mutually valuable intros. Interactions are logged with sentiment tracking (positive, neutral, needs_attention) so relationship health is visible at a glance. \n \nMost people keep contacts in their head and let relationships decay through neglect. The `stale_contacts` script cross-references contacts (who they are), interactions (when we last talked), and circles (how often we should talk) to surface outreach needs. A 30-second scan each week shows me which relationships need attention. \nSpecialized groups in `circles.yaml`founders, investors, ai_builders, creators, mentors, mentees, each have explicit relationship development strategies. For AI builders: share useful content, collaborate on open source, provide tool feedback, amplify their work. For mentors: bring specific questions, update on progress from previous advice, look for ways to add value back. These are operational instructions the agent follows when I ask \"Who should I reach out to this week?\"\nAutomation Chains: Five scripts handle recurring workflows. They chain together for compound operations. The Sunday weekly review runs three scripts in sequence: `metrics_snapshot.py` updates the numbers, `stale_contacts.py` flags relationships, `weekly_review.py` generates a summary document with completed-versus-planned, metrics trends, and next week's priorities. The content ideation chain reads recent bookmarks, checks undeveloped ideas, generates fresh suggestions, and cross-references with the content calendar to find scheduling gaps. These aren't cron jobs -- the agent runs them when I ask for a review, or I trigger them with `npm run weekly-review`. \n \nScripts that output to stdout in agent-readable format close the loop between data and action. The weekly review script doesn't just tell me what happened -- it references my goals and identifies which key results are on track, which are behind, and what to prioritize next week. The scripts read from the same files the agent reads during normal operation, so there's no data duplication or synchronization problem. \n \nAfter running the weekly review, the agent has everything it needs to update `todos.md` for next week, adjust `goals.yaml` progress numbers, and suggest content topics that align with underperforming key results. The review isn't a report -- it's the starting point for next week's planning. The automation creates a feedback loop: goals drive content, content drives metrics, metrics drive reviews, reviews drive goals.\n \n5) WHAT I GOT WRONG AND WHAT I'D DO DIFFERENTLY\nI over-engineered the schema first pass. My initial JSONL schemas had 15+ fields per entry. Most were empty. Agents struggle with sparse data -- they try to fill in fields or comment on the absence. I cut schemas to 8-10 essential fields and added optional fields only when I actually had data for them. Simpler schemas, better agent behavior.\nThe voice guide was too long at first. Version one of `tone-of-voice.md` was 1,200 lines. The agent would start strong, then drift by paragraph four as the voice instructions fell into the lost-in-middle zone. I restructured it to front-load the most distinctive patterns (signature phrases, banned words, opening patterns) in the first 100 lines, with extended examples further down. The critical rules need to be at the top, not the middle.\nModule boundaries matter more than you think. I initially had identity and brand in one module. The agent would load my entire bio when it only needed my banned words list. Splitting them into two modules cut token usage for voice-only tasks by 40%. Every module boundary is a loading decision. Get them wrong and you load too much or too little.\nAppend-only is non-negotiable. I lost three months of post engagement data early on because an agent rewrote `posts.jsonl` instead of appending to it. JSONL's append-only pattern isn't just a convention -- it's a safety mechanism. The agent can add data. It cannot destroy data. This is the most important architectural decision in the system.\n \n6) THE RESULTS AND THE PRINCIPLE BEHIND THEM\nThe real result is simpler than any metric. I open Cursor or Claude Code, start a conversation, and the AI already knows who I am, how I write, what I'm working on, and what I care about. It writes in my voice because my voice is encoded as structured data. It follows my priorities because my goals are in a YAML file it reads before suggesting what to work on. It manages my relationships because my contacts and interactions are in files it can query.\nThe principle behind all of it: this is context engineering, not prompt engineering. Prompt engineering asks \"how do I phrase this question better?\" Context engineering asks \"what information does this AI need to make the right decision, and how do I structure that information so the model actually uses it?\"\nThe shift is from optimizing individual interactions to designing information architecture. It's the difference between writing a good email and building a good filing system. One helps you once. The other helps you every time.\n \nThe entire system fits in a Git repository. Clone it to any machine, point any AI tool at it, and the operating system is running. Zero dependencies. Full portability. And because it's Git, every change is versioned, every decision is traceable, and nothing is ever truly lost.\n \nMuratcan Koylan is Context Engineer at Sully.ai, where he designs context engineering systems for healthcare AI. His on-source work on context engineering (8,000+ GitHub stars) is cited in academic research alongside Anthropic. Previously AI Agent Systems Manager at 99Ravens AI, building multi-agent systems handling 10,000+ weekly interactions.\nFramework: [Agent Skills for Context Engineering](https://github.com/muratcankoylan/Agent-Skills-for-Context-Engineering)\n \n"
      },
      "author_id": "1603551009854423040",
      "text": "https://t.co/7kZ0k7nbxI",
      "conversation_id": "2025286163641118915",
      "created_at": "2026-02-21T19:07:04.000Z",
      "edit_history_tweet_ids": [
        "2025286163641118915"
      ],
      "id": "2025286163641118915",
      "entities": {
        "urls": [
          {
            "start": 0,
            "end": 23,
            "url": "https://t.co/7kZ0k7nbxI",
            "expanded_url": "http://x.com/i/article/2025249985722224640",
            "display_url": "x.com/i/article/2025\u2026",
            "status": 500,
            "unwound_url": "https://x.com/i/article/2025249985722224640"
          }
        ]
      }
    },
    {
      "text": "@marcodices Wow, thank you! \n\nThis is my first article here. I feel like I should write more.",
      "edit_history_tweet_ids": [
        "2025314561952190737"
      ],
      "conversation_id": "2025286163641118915",
      "referenced_tweets": [
        {
          "type": "replied_to",
          "id": "2025313020331655185"
        }
      ],
      "entities": {
        "mentions": [
          {
            "start": 0,
            "end": 11,
            "username": "marcodices",
            "id": "1788219413352546304"
          }
        ]
      },
      "created_at": "2026-02-21T20:59:54.000Z",
      "in_reply_to_user_id": "1788219413352546304",
      "author_id": "1603551009854423040",
      "id": "2025314561952190737"
    },
    {
      "text": "@jeffk8900 @arscontexta I always find graph databases overrated, but recently I've started noticing useful implementations. \n\nSkill Graphs &gt; SKILLmd article is on my reading list for this weekend.",
      "edit_history_tweet_ids": [
        "2025315009111212376"
      ],
      "entities": {
        "annotations": [
          {
            "start": 126,
            "end": 137,
            "probability": 0.7091,
            "type": "Other",
            "normalized_text": "Skill Graphs"
          },
          {
            "start": 144,
            "end": 150,
            "probability": 0.5479,
            "type": "Other",
            "normalized_text": "SKILLmd"
          }
        ],
        "mentions": [
          {
            "start": 0,
            "end": 10,
            "username": "jeffk8900",
            "id": "52227134"
          },
          {
            "start": 11,
            "end": 23,
            "username": "arscontexta",
            "id": "1915489112787718144"
          }
        ]
      },
      "conversation_id": "2025286163641118915",
      "referenced_tweets": [
        {
          "type": "replied_to",
          "id": "2025306263454974284"
        }
      ],
      "created_at": "2026-02-21T21:01:41.000Z",
      "in_reply_to_user_id": "52227134",
      "author_id": "1603551009854423040",
      "id": "2025315009111212376"
    },
    {
      "text": "@LinkedEric Thank you!",
      "edit_history_tweet_ids": [
        "2025322065859940539"
      ],
      "conversation_id": "2025286163641118915",
      "referenced_tweets": [
        {
          "type": "replied_to",
          "id": "2025320377002639763"
        }
      ],
      "entities": {
        "mentions": [
          {
            "start": 0,
            "end": 11,
            "username": "LinkedEric",
            "id": "1297716938542583808"
          }
        ]
      },
      "created_at": "2026-02-21T21:29:43.000Z",
      "in_reply_to_user_id": "1297716938542583808",
      "author_id": "1603551009854423040",
      "id": "2025322065859940539"
    },
    {
      "text": "@IntuitMachine Glad you liked it",
      "edit_history_tweet_ids": [
        "2025322098324111726"
      ],
      "conversation_id": "2025286163641118915",
      "referenced_tweets": [
        {
          "type": "replied_to",
          "id": "2025317657688326533"
        }
      ],
      "entities": {
        "mentions": [
          {
            "start": 0,
            "end": 14,
            "username": "IntuitMachine",
            "id": "3027431134"
          }
        ]
      },
      "created_at": "2026-02-21T21:29:51.000Z",
      "in_reply_to_user_id": "3027431134",
      "author_id": "1603551009854423040",
      "id": "2025322098324111726"
    },
    {
      "text": "@WayneVaughan Nice! Show what you built after applying the concepts \ud83e\udee1",
      "edit_history_tweet_ids": [
        "2025337871385723242"
      ],
      "conversation_id": "2025286163641118915",
      "referenced_tweets": [
        {
          "type": "replied_to",
          "id": "2025337453335429271"
        }
      ],
      "entities": {
        "mentions": [
          {
            "start": 0,
            "end": 13,
            "username": "WayneVaughan",
            "id": "9926812"
          }
        ]
      },
      "created_at": "2026-02-21T22:32:32.000Z",
      "in_reply_to_user_id": "9926812",
      "author_id": "1603551009854423040",
      "id": "2025337871385723242"
    },
    {
      "text": "@jeffreyhuber i know i know...\n\ncursor as a database",
      "edit_history_tweet_ids": [
        "2025355419938443732"
      ],
      "conversation_id": "2025286163641118915",
      "referenced_tweets": [
        {
          "type": "replied_to",
          "id": "2025348520203747580"
        }
      ],
      "entities": {
        "mentions": [
          {
            "start": 0,
            "end": 13,
            "username": "jeffreyhuber",
            "id": "15728306"
          }
        ]
      },
      "created_at": "2026-02-21T23:42:16.000Z",
      "in_reply_to_user_id": "15728306",
      "author_id": "1603551009854423040",
      "id": "2025355419938443732"
    },
    {
      "text": "@jeffreyhuber \"File systems killed databases\"",
      "edit_history_tweet_ids": [
        "2025358393397932358"
      ],
      "conversation_id": "2025286163641118915",
      "referenced_tweets": [
        {
          "type": "replied_to",
          "id": "2025357942548300139"
        }
      ],
      "entities": {
        "mentions": [
          {
            "start": 0,
            "end": 13,
            "username": "jeffreyhuber",
            "id": "15728306"
          }
        ]
      },
      "created_at": "2026-02-21T23:54:04.000Z",
      "in_reply_to_user_id": "15728306",
      "author_id": "1603551009854423040",
      "id": "2025358393397932358"
    },
    {
      "text": "@mindragon This means a lot. \nThank you for reading it the way it was built.",
      "edit_history_tweet_ids": [
        "2025372971079016519"
      ],
      "conversation_id": "2025286163641118915",
      "referenced_tweets": [
        {
          "type": "replied_to",
          "id": "2025371000800452944"
        }
      ],
      "entities": {
        "mentions": [
          {
            "start": 0,
            "end": 10,
            "username": "mindragon",
            "id": "28648160"
          }
        ]
      },
      "created_at": "2026-02-22T00:52:00.000Z",
      "in_reply_to_user_id": "28648160",
      "author_id": "1603551009854423040",
      "id": "2025372971079016519"
    },
    {
      "text": "@tpae This is my personal side project. I'm not building anything to scale lol",
      "edit_history_tweet_ids": [
        "2025399714321973387"
      ],
      "conversation_id": "2025286163641118915",
      "referenced_tweets": [
        {
          "type": "replied_to",
          "id": "2025398226845905390"
        }
      ],
      "entities": {
        "mentions": [
          {
            "start": 0,
            "end": 5,
            "username": "tpae",
            "id": "34378256"
          }
        ]
      },
      "created_at": "2026-02-22T02:38:16.000Z",
      "in_reply_to_user_id": "34378256",
      "author_id": "1603551009854423040",
      "id": "2025399714321973387"
    },
    {
      "text": "@crabhive Thank you. \n\nI used Nano Banana with Opus prompts",
      "edit_history_tweet_ids": [
        "2025417385453257193"
      ],
      "entities": {
        "annotations": [
          {
            "start": 30,
            "end": 40,
            "probability": 0.4991,
            "type": "Person",
            "normalized_text": "Nano Banana"
          },
          {
            "start": 47,
            "end": 50,
            "probability": 0.8993,
            "type": "Other",
            "normalized_text": "Opus"
          }
        ],
        "mentions": [
          {
            "start": 0,
            "end": 9,
            "username": "crabhive",
            "id": "2013065766971609088"
          }
        ]
      },
      "conversation_id": "2025286163641118915",
      "referenced_tweets": [
        {
          "type": "replied_to",
          "id": "2025410097602535762"
        }
      ],
      "created_at": "2026-02-22T03:48:29.000Z",
      "in_reply_to_user_id": "2013065766971609088",
      "author_id": "1603551009854423040",
      "id": "2025417385453257193"
    },
    {
      "text": "@kermankohli @jeffreyhuber I believe I didn't do a good job with the article's title. I'm not opposed to databases of any kind and don't think file systems can replace databases; that would be silly.\n\nThis has been my side project and I'm using/improving/evolving this in Cursor. It literally started as a",
      "edit_history_tweet_ids": [
        "2025432678388953455"
      ],
      "note_tweet": {
        "text": "I believe I didn't do a good job with the article's title. I'm not opposed to databases of any kind and don't think file systems can replace databases; that would be silly.\n\nThis has been my side project and I'm using/improving/evolving this in Cursor. It literally started as a hobby project, and then I found more and more value in it. If I want to scale this i will need to build databases with Chrome, Convex, Supabase etc. \n\nBut my point is that as an entry user, you don't need to deal with databases; file systems are eay to build and update. That's why for example I don't use Claude Code for this project, I prefer Cursor because I can easily manage everything,see the before/afters, manually edit. \n\nAnd if you read the post, I don't just use markdowns. They are all connected in some way, some with Skills files, some with scripts connecting JSONs to Markdown.\n\nIf you want to build a system that would scale millions of rows or users, go build with databases. If you need a solution, a project that would solve your today's problems, start with filesystems. \n\nIt shouldn't be this hard to understand; this is neither scalable with this version nor a SaaS project."
      },
      "entities": {
        "annotations": [
          {
            "start": 272,
            "end": 277,
            "probability": 0.8546,
            "type": "Other",
            "normalized_text": "Cursor"
          }
        ],
        "mentions": [
          {
            "start": 0,
            "end": 12,
            "username": "kermankohli",
            "id": "143624329"
          },
          {
            "start": 13,
            "end": 26,
            "username": "jeffreyhuber",
            "id": "15728306"
          }
        ]
      },
      "conversation_id": "2025286163641118915",
      "referenced_tweets": [
        {
          "type": "replied_to",
          "id": "2025428874340040722"
        }
      ],
      "created_at": "2026-02-22T04:49:15.000Z",
      "in_reply_to_user_id": "143624329",
      "author_id": "1603551009854423040",
      "id": "2025432678388953455"
    }
  ],
  "users": {
    "1603551009854423040": {
      "id": "1603551009854423040",
      "name": "Muratcan Koylan",
      "username": "koylanai"
    },
    "167881506": {
      "id": "167881506",
      "name": "Muhammad Ali Jinnah (RA)",
      "username": "MrJinnah"
    },
    "1259466826339225603": {
      "id": "1259466826339225603",
      "name": "Markus J. Kaiser",
      "username": "m_j_kai"
    },
    "829836957882732548": {
      "id": "829836957882732548",
      "name": "The Art of Orangepilling",
      "username": "maximalismo_btc"
    },
    "706950859599454208": {
      "id": "706950859599454208",
      "name": "st4rgard3n",
      "username": "KyleSt4rgarden"
    },
    "15728306": {
      "id": "15728306",
      "name": "Jeff Huber",
      "username": "jeffreyhuber"
    },
    "1435885089225904134": {
      "id": "1435885089225904134",
      "name": "Vladi",
      "username": "w5w6drixenbbbb"
    },
    "1551055953482719233": {
      "id": "1551055953482719233",
      "name": "Product Thor",
      "username": "ProductThor"
    },
    "2739672962": {
      "id": "2739672962",
      "name": "Mindset Forge\u2692\ufe0f",
      "username": "Mindset_Forge_"
    },
    "943724756758679552": {
      "id": "943724756758679552",
      "name": "Todd Kuehnl",
      "username": "ToddKuehnl"
    },
    "1837949208894062592": {
      "id": "1837949208894062592",
      "name": "G\u00f6rkem Bonomo",
      "username": "smandesignco"
    },
    "2024719760681029632": {
      "id": "2024719760681029632",
      "name": "Yvette Carlisle",
      "username": "YvetteC35382"
    },
    "62625948": {
      "id": "62625948",
      "name": "Manne Laukkanen, PhD \ud83c\uddeb\ud83c\uddee \ud83c\uddfa\ud83c\udde6",
      "username": "ManneLaukkanen"
    },
    "87331817": {
      "id": "87331817",
      "name": "Cassandra Hartford",
      "username": "SpaceCoastCRE"
    },
    "1720665183188922368": {
      "id": "1720665183188922368",
      "name": "Grok",
      "username": "grok"
    },
    "1596061865133559808": {
      "id": "1596061865133559808",
      "name": "Neo",
      "username": "tianyuzhang1214"
    },
    "2020646803826483200": {
      "id": "2020646803826483200",
      "name": "Leo Tavares",
      "username": "LeoTava8"
    },
    "310418943": {
      "id": "310418943",
      "name": "pablo",
      "username": "safetnsr"
    },
    "143624329": {
      "id": "143624329",
      "name": "kerman kohli",
      "username": "kermankohli"
    },
    "29449204": {
      "id": "29449204",
      "name": "AndyDentPerth",
      "username": "AndyDentPerth"
    },
    "12680172": {
      "id": "12680172",
      "name": "Micah",
      "username": "micahl"
    },
    "14589854": {
      "id": "14589854",
      "name": "B\u039eN",
      "username": "ben3bil"
    },
    "756537588": {
      "id": "756537588",
      "name": "Hamza Wazarmas",
      "username": "Hawazarmas"
    },
    "1765168270787629056": {
      "id": "1765168270787629056",
      "name": "Darren Addy",
      "username": "RabbitHoleXplor"
    },
    "1377330000987254786": {
      "id": "1377330000987254786",
      "name": "Some Noise",
      "username": "somenoise"
    },
    "1419619687168544768": {
      "id": "1419619687168544768",
      "name": "Pranav Mishra",
      "username": "pranavmishra28"
    },
    "241022374": {
      "id": "241022374",
      "name": "yxssxn",
      "username": "yxssxn"
    },
    "156709375": {
      "id": "156709375",
      "name": "Jorge",
      "username": "tebayoso"
    },
    "1525564618399043584": {
      "id": "1525564618399043584",
      "name": "Kitt",
      "username": "ICT_Concepts"
    },
    "3702582618": {
      "id": "3702582618",
      "name": "Divyam Khandelwal",
      "username": "khandelwaldiv"
    },
    "2013065766971609088": {
      "id": "2013065766971609088",
      "name": "Wil Gibson",
      "username": "crabhive"
    },
    "71733178": {
      "id": "71733178",
      "name": "Zak El Fassi",
      "username": "zakelfassi"
    },
    "28648160": {
      "id": "28648160",
      "name": "JeffersonNunn.eth",
      "username": "mindragon"
    },
    "2020418347968696320": {
      "id": "2020418347968696320",
      "name": "SF Engg",
      "username": "oleSFEnggo"
    },
    "34378256": {
      "id": "34378256",
      "name": "tpae",
      "username": "tpae"
    },
    "328577430": {
      "id": "328577430",
      "name": "usman",
      "username": "usmanshabbir"
    },
    "746644996556718080": {
      "id": "746644996556718080",
      "name": "Timrot Ashan",
      "username": "TimrotAshan"
    },
    "1222314809481400320": {
      "id": "1222314809481400320",
      "name": "rasha",
      "username": "rasha_hantash"
    },
    "2017975411620089856": {
      "id": "2017975411620089856",
      "name": "clawcian",
      "username": "clawcian"
    },
    "2023486384099700736": {
      "id": "2023486384099700736",
      "name": "ArticleReplay",
      "username": "articlereplay"
    },
    "1696076591711858688": {
      "id": "1696076591711858688",
      "name": "\u2026",
      "username": "myoldbookmarks"
    },
    "376665053": {
      "id": "376665053",
      "name": "hamed",
      "username": "hamedmp"
    },
    "1852535030217846784": {
      "id": "1852535030217846784",
      "name": "Chan Nguyen",
      "username": "chanc0x12c"
    },
    "1611769679046926337": {
      "id": "1611769679046926337",
      "name": "Max Vishnevskii",
      "username": "maxvsnv"
    },
    "1552381326229110784": {
      "id": "1552381326229110784",
      "name": "6\ufe0f\u20e3",
      "username": "hi_im_six"
    },
    "873948766419779584": {
      "id": "873948766419779584",
      "name": "Ash (\ud83c\uddfa\ud83c\udde6,\ud83e\udd16)",
      "username": "incyd__"
    },
    "9926812": {
      "id": "9926812",
      "name": "Wayne Vaughan",
      "username": "WayneVaughan"
    },
    "52227134": {
      "id": "52227134",
      "name": "Jeff Kiefer",
      "username": "jeffk8900"
    },
    "30199939": {
      "id": "30199939",
      "name": "(El Capitano) Otman Mechbal, PM & AI Consultant",
      "username": "El_Capitano_O"
    },
    "3027431134": {
      "id": "3027431134",
      "name": "Carlos E. Perez",
      "username": "IntuitMachine"
    },
    "1297716938542583808": {
      "id": "1297716938542583808",
      "name": "Eric",
      "username": "LinkedEric"
    },
    "1521177264964222977": {
      "id": "1521177264964222977",
      "name": "Borz_Salim\ud83d\udc3a",
      "username": "BorzSalim"
    },
    "941759689045499905": {
      "id": "941759689045499905",
      "name": "Pedro",
      "username": "sillydarket"
    },
    "1788219413352546304": {
      "id": "1788219413352546304",
      "name": "Marco Di Cesare",
      "username": "marcodices"
    },
    "659333": {
      "id": "659333",
      "name": "Robert Mao",
      "username": "mave99a"
    },
    "10430022": {
      "id": "10430022",
      "name": "Carl Sverre",
      "username": "carlsverre"
    },
    "33521530": {
      "id": "33521530",
      "name": "swyx",
      "username": "swyx"
    },
    "2821275879": {
      "id": "2821275879",
      "name": "George",
      "username": "odysseus0z"
    }
  },
  "thread_fetch_error": null
}